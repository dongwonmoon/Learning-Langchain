{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16306714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인덱싱 1회차: {'num_added': 2, 'num_updated': 0, 'num_skipped': 0, 'num_deleted': 0}\n",
      "인덱싱 2회차: {'num_added': 0, 'num_updated': 0, 'num_skipped': 2, 'num_deleted': 0}\n",
      "인덱싱 3회차: {'num_added': 1, 'num_updated': 0, 'num_skipped': 1, 'num_deleted': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anseh/.pyenv/versions/langchain/lib/python3.11/site-packages/langchain_core/indexing/api.py:389: UserWarning: Using SHA-1 for document hashing. SHA-1 is *not* collision-resistant; a motivated attacker can construct distinct inputs that map to the same fingerprint. If this matters in your threat model, switch to a stronger algorithm such as 'blake2b', 'sha256', or 'sha512' by specifying  `key_encoder` parameter in the the `index` or `aindex` function. \n",
      "  _warn_about_sha1()\n"
     ]
    }
   ],
   "source": [
    "from langchain.indexes import SQLRecordManager, index\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "connection = \"postgresql+psycopg2://langchain:langchain@localhost:6024/langchain\"\n",
    "collection_name = \"my_docs\"\n",
    "embeddings_model = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "namespace = \"my_docs_namespace\"\n",
    "\n",
    "vectorstore = PGVector(\n",
    "    embeddings=embeddings_model,\n",
    "    collection_name=collection_name,\n",
    "    connection=connection,\n",
    "    use_jsonb=True,\n",
    ")\n",
    "\n",
    "record_manager = SQLRecordManager(\n",
    "    namespace,\n",
    "    db_url=\"postgresql+psycopg2://langchain:langchain@localhost:6024/langchain\",\n",
    ")\n",
    "\n",
    "# 스키마가 없으면 생성\n",
    "record_manager.create_schema()\n",
    "\n",
    "# 문서 생성\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"there are cats in the pond\",\n",
    "        metadata={\"id\": 1, \"source\": \"cats.txt\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"ducks are also found in the pond\",\n",
    "        metadata={\"id\": 2, \"source\": \"ducks.txt\"},\n",
    "    ),\n",
    "]\n",
    "\n",
    "# 문서 인덱싱 1회차\n",
    "index_1 = index(\n",
    "    docs,\n",
    "    record_manager,\n",
    "    vectorstore,\n",
    "    cleanup=\"incremental\",  # 문서 중복 방지\n",
    "    source_id_key=\"source\",  # 출처를 source_id로 사용\n",
    ")\n",
    "\n",
    "print(\"인덱싱 1회차:\", index_1)\n",
    "\n",
    "# 문서 인덱싱 2회차, 중복 문서 생성 안 됨\n",
    "index_2 = index(\n",
    "    docs,\n",
    "    record_manager,\n",
    "    vectorstore,\n",
    "    cleanup=\"incremental\",\n",
    "    source_id_key=\"source\",\n",
    ")\n",
    "\n",
    "print(\"인덱싱 2회차:\", index_2)\n",
    "\n",
    "# 문서를 수정하면 새 버전을 저장하고, 출처가 같은 기존 문서는 삭제\n",
    "\n",
    "docs[0].page_content = \"I just modified this document!\"\n",
    "\n",
    "index_3 = index(\n",
    "    docs,\n",
    "    record_manager,\n",
    "    vectorstore,\n",
    "    cleanup=\"incremental\",\n",
    "    source_id_key=\"source\",\n",
    ")\n",
    "\n",
    "print(\"인덱싱 3회차:\", index_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
