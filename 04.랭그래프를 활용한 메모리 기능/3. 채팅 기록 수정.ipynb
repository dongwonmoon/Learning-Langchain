{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4689eafb",
   "metadata": {},
   "source": [
    "### 메시지 축약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824c32cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='당신은 친절한 어시스턴트입니다.', additional_kwargs={}, response_metadata={}), HumanMessage(content='안녕하세요! 나는 민혁입니다.', additional_kwargs={}, response_metadata={}), AIMessage(content='안녕하세요!', additional_kwargs={}, response_metadata={}), HumanMessage(content='바닐라 아이스크림을 좋아해요.', additional_kwargs={}, response_metadata={}), AIMessage(content='좋네요!', additional_kwargs={}, response_metadata={}), HumanMessage(content='2 + 2는 얼마죠?', additional_kwargs={}, response_metadata={}), AIMessage(content='4입니다.', additional_kwargs={}, response_metadata={}), HumanMessage(content='고마워요.', additional_kwargs={}, response_metadata={}), AIMessage(content='천만에요!', additional_kwargs={}, response_metadata={}), HumanMessage(content='즐거운가요?', additional_kwargs={}, response_metadata={}), AIMessage(content='예!', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage,\n",
    "    trim_messages,\n",
    ")\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# 샘플 메시지 설정\n",
    "messages = [\n",
    "    SystemMessage(content=\"당신은 친절한 어시스턴트입니다.\"),\n",
    "    HumanMessage(content=\"안녕하세요! 나는 민혁입니다.\"),\n",
    "    AIMessage(content=\"안녕하세요!\"),\n",
    "    HumanMessage(content=\"바닐라 아이스크림을 좋아해요.\"),\n",
    "    AIMessage(content=\"좋네요!\"),\n",
    "    HumanMessage(content=\"2 + 2는 얼마죠?\"),\n",
    "    AIMessage(content=\"4입니다.\"),\n",
    "    HumanMessage(content=\"고마워요.\"),\n",
    "    AIMessage(content=\"천만에요!\"),\n",
    "    HumanMessage(content=\"즐거운가요?\"),\n",
    "    AIMessage(content=\"예!\"),\n",
    "]\n",
    "\n",
    "# 축약 설정\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=65,  # max_tokens 바꿔서 실험\n",
    "    strategy=\"last\",\n",
    "    token_counter=ChatOllama(model=\"gemma3n:e2b\"),\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\",\n",
    ")\n",
    "\n",
    "# 축약 적용\n",
    "trimmed = trimmer.invoke(messages)\n",
    "print(trimmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0209d4",
   "metadata": {},
   "source": [
    "### 메시지 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c456db71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 메시지: [HumanMessage(content='예시 입력', additional_kwargs={}, response_metadata={}, name='example_user', id='2'), HumanMessage(content='실제 입력', additional_kwargs={}, response_metadata={}, name='bob', id='4')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    filter_messages,\n",
    ")\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# 샘플 메시지\n",
    "messages = [\n",
    "    SystemMessage(content=\"당신은 친절한 어시스턴트입니다.\", id=\"1\"),\n",
    "    HumanMessage(content=\"예시 입력\", id=\"2\", name=\"example_user\"),\n",
    "    AIMessage(content=\"예시 출력\", id=\"3\", name=\"example_assistant\"),\n",
    "    HumanMessage(content=\"실제 입력\", id=\"4\", name=\"bob\"),\n",
    "    AIMessage(content=\"실제 출력\", id=\"5\", name=\"alice\"),\n",
    "]\n",
    "\n",
    "# 사용자 메시지만 필터링\n",
    "human_messages = filter_messages(messages, include_types=\"human\")\n",
    "print(\"사용자 메시지:\", human_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dfe48e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "이름에 example이 포함되지 않은 메시지: [SystemMessage(content='당신은 친절한 어시스턴트입니다.', additional_kwargs={}, response_metadata={}, id='1'), HumanMessage(content='실제 입력', additional_kwargs={}, response_metadata={}, name='bob', id='4'), AIMessage(content='실제 출력', additional_kwargs={}, response_metadata={}, name='alice', id='5')]\n"
     ]
    }
   ],
   "source": [
    "# 특정 이름의 메시지 제외\n",
    "excluded_names = filter_messages(\n",
    "    messages, exclude_names=[\"example_user\", \"example_assistant\"]\n",
    ")\n",
    "print(\"\\n이름에 example이 포함되지 않은 메시지:\", excluded_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1873880f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "특정 유형과 ID로 필터링한 메시지: [HumanMessage(content='예시 입력', additional_kwargs={}, response_metadata={}, name='example_user', id='2'), HumanMessage(content='실제 입력', additional_kwargs={}, response_metadata={}, name='bob', id='4'), AIMessage(content='실제 출력', additional_kwargs={}, response_metadata={}, name='alice', id='5')]\n"
     ]
    }
   ],
   "source": [
    "# 유형과 ID로 필터링\n",
    "filtered_messages = filter_messages(\n",
    "    messages, include_types=[\"human\", \"ai\"], exclude_ids=[\"3\"]\n",
    ")\n",
    "print(\"\\n특정 유형과 ID로 필터링한 메시지:\", filtered_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40bdca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선언형 구성\n",
    "model = ChatOllama(model=\"gemma3n:e2b\")\n",
    "filter_ = filter_messages(exclude_names=[\"example_user\", \"example_assistant\"])\n",
    "chain = filter_ | model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea508b88",
   "metadata": {},
   "source": [
    "### 연속된 메시지 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f14cbfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='당신은 친절한 어시스턴트입니다.\\n항상 농담으로 대답하세요.', additional_kwargs={}, response_metadata={}), HumanMessage(content=[{'type': 'text', 'text': '어떤 피자가 제일 맛있나요?'}, '어떤 햄버거가 가장 맛있나요?'], additional_kwargs={}, response_metadata={}), AIMessage(content='나는 항상 너만 \"고르곤졸라\"\\n너가 \"버거\" 싶어', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    merge_message_runs,\n",
    ")\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# 동일한 유형의 연속된 메시지 예제\n",
    "messages = [\n",
    "    SystemMessage(content=\"당신은 친절한 어시스턴트입니다.\"),\n",
    "    SystemMessage(content=\"항상 농담으로 대답하세요.\"),\n",
    "    HumanMessage(content=[{\"type\": \"text\", \"text\": \"어떤 피자가 제일 맛있나요?\"}]),\n",
    "    HumanMessage(content=\"어떤 햄버거가 가장 맛있나요?\"),\n",
    "    AIMessage(content='나는 항상 너만 \"고르곤졸라\"'),\n",
    "    AIMessage(content='너가 \"버거\" 싶어'),\n",
    "]\n",
    "\n",
    "# 연속된 메시지를 병합\n",
    "merged = merge_message_runs(messages)\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8fb780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선언형 구성\n",
    "model = ChatOllama(model=\"gemma3n:e2b\")\n",
    "merger = merge_message_runs()\n",
    "chain = merger | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186b52d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
